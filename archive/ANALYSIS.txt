HOCKEY GAME PYTHON SCRIPTS ANALYSIS
====================================

FILE ASSESSMENT:
---------------

1. extract_information_from_table.py (7320 bytes)
   STATUS: SALVAGE + REFACTOR
   - GOOD: Solid dataclasses, type hints, regex parsing
   - GOOD: Handles player info + season stats
   - BAD: Hardcoded example data (lines 103-148)
   - BAD: Doesn't read data_player.txt (exists with real data)
   - BAD: Directus API credentials hardcoded
   - BAD: Mixed concerns (parsing + API calls)
   - ISSUES: No error handling for API calls, no validation

2. claudtest.py (1805 bytes)
   STATUS: DELETE
   - BROKEN: Missing imports (WebDriverWait, EC)
   - BAD: Uses pyautogui + pyperclip (fragile GUI automation)
   - BAD: Hardcoded sleeps, no error handling
   - BAD: Writes to clipboard (unreliable)
   - REPLACED BY: Better scraping in fetchdata.py

3. fetchdata.py (1262 bytes)
   STATUS: SALVAGE + REFACTOR
   - GOOD: Uses webdriver_manager (auto ChromeDriver)
   - GOOD: Simple page_source extraction
   - BAD: Incomplete (doesn't parse data)
   - BAD: Hardcoded URL
   - ISSUE: No headless mode, no error handling

4. test_player_.py (905 bytes)
   STATUS: DELETE (rename to .js if needed)
   - WRONG: JavaScript code with .py extension
   - Content: Directus SDK client code
   - Action: Move to .js or delete

DATA FILES DISCOVERED:
---------------------
- data_player.txt: Multiple players in text format (GOLD)
- scraped_content.txt: Steven Stamkos HTML scrape

REFACTORING PLAN:
----------------

Create unified pipeline in src/python/:

1. scraper.py
   - Selenium-based scraper (from fetchdata.py)
   - Headless mode, configurable URLs
   - Error handling, retries
   - ASCII-only output (Windows compatible)

2. parser.py
   - Text parser (from extract_information_from_table.py)
   - Reads data_player.txt
   - Dataclasses for Player/Season/Goalie
   - Validation logic

3. api_client.py
   - Directus API interactions
   - Environment variables for credentials
   - Batch operations
   - Error handling

4. pipeline.py
   - Orchestrates: scrape -> parse -> upload
   - Single execution principle
   - Comprehensive validation
   - Exit codes for success/failure

DECISIONS:
---------
- DELETE: claudtest.py (fragile, replaced)
- DELETE: test_player_.py (wrong extension)
- REFACTOR: extract_information_from_table.py -> parser.py
- REFACTOR: fetchdata.py -> scraper.py
- CREATE: api_client.py, pipeline.py

Python 3.8+ features OK
Windows compatible (ASCII only)
Minimal dependencies: requests, selenium, webdriver_manager
